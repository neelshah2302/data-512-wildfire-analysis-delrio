{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AQI Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used to extract AQI values from 1963 to 2023 around a specific city. I am using the reference code provided by the Prof for the data extraction which uses a US EPA API call to get the AQI information based on the fips for Del Rio, Texas. \n",
    "\n",
    "The AQI extraction will be done for each year and run from 1963 to 2023 for a specific fips number which we will obtain by fining the local AQI measurement sites around Del Rio, Texas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AQI Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN8rKPYvpDvS",
    "tags": []
   },
   "source": [
    "# US EPA Air Quality System API Example\n",
    "This example illustrates how to request data from the US Environmental Protection Agency (EPA) Air Quality Service (AQS) API. This is a historical API and does not provide real-time air quality data. The [documentation](https://aqs.epa.gov/aqsweb/documents/data_api.html) for the API provides definitions of the different call parameter and examples of the various calls that can be made to the API.\n",
    "\n",
    "This notebook works systematically through example calls, requesting an API key, using 'list' to get various IDs and parameter values, and using 'daily summary' to get summary data that meets specific condistions. The notebook contains example function definitions that could be reused in other code. In general, the notebook explains each step along the way, referring back to possible output. Some of the explanations are tailored to the specific example requests of the API. Changing values to explore the results of the API is probably useful, but that will result in some explanations being out of sync with the outputs.\n",
    "\n",
    "The US EPA was created in the early 1970's. The EPA reports that they only started broad based monitoring with standardized quality assurance procedures in the 1980's. Many counties will have data starting somewhere between 1983 and 1988. However, some counties still do not have any air quality monitoring stations. The API helps resolve this by providing calls to search for monitoring stations and data using either station ids, or a county designation or a geographic bounding box. This example code provides examples of the county based and bounding box based API calls. Some [additional information on the Air Quality System can be found in the EPA FAQ](https://www.epa.gov/outdoor-air-quality-data/frequent-questions-about-airdata) on the system.\n",
    "\n",
    "The end goal of this example is to get to some values that we might use for the Air Quality Index or AQI. You might see this reported on the news, most often around smog, but more frequently with regard to smoke. The AQI index is meant to tell us something about how healthy or clean the air is on any day. The AQI is actually a somewhat complext measure. When I started this example I looked up [how to calculate the AQI](https://www.airnow.gov/sites/default/files/2020-05/aqi-technical-assistance-document-sept2018.pdf) so that I would know roughly what goes into that value.\n",
    "\n",
    "\n",
    "## License\n",
    "This code example was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.1 - September 5, 2023\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-NuXRys5pDvX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    These are standard python modules\n",
    "#\n",
    "#import json, time, urllib.parse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json, time\n",
    "#\n",
    "#    The 'requests' module is a distribution module for making web requests.\n",
    "#\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "a5Gpy6kzpDvY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "#    This is the root of all AQS API URLs\n",
    "#\n",
    "API_REQUEST_URL = 'https://aqs.epa.gov/data/api'\n",
    "\n",
    "#\n",
    "#    These are 'actions' we can ask the API to take or requests that we can make of the API\n",
    "#\n",
    "#    Sign-up request - generally only performed once - unless you lose your key\n",
    "API_ACTION_SIGNUP = '/signup?email={email}'\n",
    "#\n",
    "#    List actions provide information on API parameter values that are required by some other actions/requests\n",
    "API_ACTION_LIST_CLASSES = '/list/classes?email={email}&key={key}'\n",
    "API_ACTION_LIST_PARAMS = '/list/parametersByClass?email={email}&key={key}&pc={pclass}'\n",
    "API_ACTION_LIST_SITES = '/list/sitesByCounty?email={email}&key={key}&state={state}&county={county}'\n",
    "#\n",
    "#    Monitor actions are requests for monitoring stations that meet specific criteria\n",
    "API_ACTION_MONITORS_COUNTY = '/monitors/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_MONITORS_BOX = '/monitors/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "#\n",
    "#    Summary actions are requests for summary data. These are for daily summaries\n",
    "API_ACTION_DAILY_SUMMARY_COUNTY = '/dailyData/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_DAILY_SUMMARY_BOX = '/dailyData/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "#\n",
    "#    It is always nice to be respectful of a free data resource.\n",
    "#    We're going to observe a 100 requests per minute limit - which is fairly nice\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "#\n",
    "#\n",
    "#    This is a template that covers most of the parameters for the actions we might take, from the set of actions\n",
    "#    above. In the examples below, most of the time parameters can either be supplied as individual values to a\n",
    "#    function - or they can be set in a copy of the template and passed in with the template.\n",
    "#\n",
    "AQS_REQUEST_TEMPLATE = {\n",
    "    \"email\":      \"\",\n",
    "    \"key\":        \"\",\n",
    "    \"state\":      \"\",     # the two digit state FIPS # as a string\n",
    "    \"county\":     \"\",     # the three digit county FIPS # as a string\n",
    "    \"begin_date\": \"\",     # the start of a time window in YYYYMMDD format\n",
    "    \"end_date\":   \"\",     # the end of a time window in YYYYMMDD format, begin_date and end_date must be in the same year\n",
    "    \"minlat\":    0.0,\n",
    "    \"maxlat\":    0.0,\n",
    "    \"minlon\":    0.0,\n",
    "    \"maxlon\":    0.0,\n",
    "    \"param\":     \"\",     # a list of comma separated 5 digit codes, max 5 codes requested\n",
    "    \"pclass\":    \"\"      # parameter class is only used by the List calls\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQr0uv9BpDvZ"
   },
   "source": [
    "## Making a sign-up request\n",
    "\n",
    "Before you can use the API you need to request a key. You will use an email address to make the request. The EPA then sends a confirmation email link and a 'key' that you use for all other requests.\n",
    "\n",
    "You only need to sign-up once, unless you want to invalidate your current key (by getting a new key) or you lose your key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_LUYRanRpDvZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the sign-up request. The parameters are standardized so that this function definition matches\n",
    "#    all of the others. However, the easiest way to call this is to simply call this function with your preferred\n",
    "#    email address.\n",
    "#\n",
    "def request_signup(email_address = None,\n",
    "                   endpoint_url = API_REQUEST_URL,\n",
    "                   endpoint_action = API_ACTION_SIGNUP,\n",
    "                   request_template = AQS_REQUEST_TEMPLATE,\n",
    "                   headers = None):\n",
    "\n",
    "    # Make sure we have a string - if you don't have access to this email addres, things might go badly for you\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_signup()'\")\n",
    "\n",
    "    # Compose the signup url - create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Og8Hoz_wpDvZ",
    "outputId": "7449f189-0673-4477-e84b-609ad6df72e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting SIGNUP ...\n",
      "{\n",
      "    \"Header\": [\n",
      "        {\n",
      "            \"status\": \"Success\",\n",
      "            \"request_time\": \"2023-11-07T17:55:24-05:00\",\n",
      "            \"url\": \"https://aqs.epa.gov/data/api/signup?email=nshah23@uw.edu\"\n",
      "        }\n",
      "    ],\n",
      "    \"Data\": [\n",
      "        \"You should receive a registration confirmation email with a link for confirming your email shortly.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#    A SIGNUP request is only to be done once, to request a key. A key is sent to that email address and needs to be confirmed with a click through\n",
    "#    This code should probably be commented out after you've made your key request to make sure you don't accidentally make a new sign-up request\n",
    "#\n",
    "# print(\"Requesting SIGNUP ...\")\n",
    "# response = request_signup(\"nshah23@uw.edu\")\n",
    "# print(json.dumps(response,indent=4))\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ok3FJrY3pDva"
   },
   "source": [
    "A response to the signup request might look something like this.\n",
    "\n",
    "\n",
    "    Requesting SIGNUP ...\n",
    "    {\n",
    "        \"Header\": [\n",
    "            {\n",
    "                \"status\": \"Success\",\n",
    "                \"request_time\": \"2023-08-07T17:03:27-04:00\",\n",
    "                \"url\": \"https://aqs.epa.gov/data/api/signup?email=dwmc@uw.edu\"\n",
    "            }\n",
    "        ],\n",
    "        \"Data\": [\n",
    "            \"You should receive a registration confirmation email with a link for confirming your email shortly.\"\n",
    "        ]\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zp9_CPGHpDvb"
   },
   "outputs": [],
   "source": [
    "# Defining username and APIKey\n",
    "USERNAME = \"nshah23@uw.edu\"\n",
    "APIKEY = \"greyfox41\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAX4R8MopDvb"
   },
   "source": [
    "## Making a list request\n",
    "Once you have a key, the next thing is to get information about the different types of air quality monitoring (sensors) and the different places where we might find air quality stations. The monitoring system is complex and changes all the time. The EPA implementation allows an API user to find changes to monitoring sites and sensors by making requests - maybe monthly, or daily. This API approach is probably better than having the EPA publish documentation that may be out of date as soon as it hits a web page. The one problem here is that some of the responses rely on jargon or terms-of-art. That is, one needs to know a bit about the way atmospheric sciece works to understand some of the terms. ... Good thing we can use the web to search for terms we don't know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4rCnUnIlpDvb"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the list request. There are several versions of the list request that only require email and key.\n",
    "#    This code sets the default action/requests to list the groups or parameter class descriptors. Having those descriptors\n",
    "#    allows one to request the individual (proprietary) 5 digit codes for individual air quality measures by using the\n",
    "#    param request. Some code in later cells will illustrate those requests.\n",
    "#\n",
    "def request_list_info(email_address = None, key = None,\n",
    "                      endpoint_url = API_REQUEST_URL,\n",
    "                      endpoint_action = API_ACTION_LIST_CLASSES,\n",
    "                      request_template = AQS_REQUEST_TEMPLATE,\n",
    "                      headers = None):\n",
    "\n",
    "    #  Make sure we have email and key - at least\n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "\n",
    "    # For the basic request we need an email address and a key\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_list_info()'\")\n",
    "    if not request_template['key']:\n",
    "        raise Exception(\"Must supply a key to call 'request_list_info()'\")\n",
    "\n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmqIEejvpDvc",
    "outputId": "74a59652-dee1-4f63-f117-54894d03c8c9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#   The default should get us a list of the various groups or classes of sensors. These classes are user defined names for clustors of\n",
    "#   sensors that might be part of a package or default air quality sensing station. We need a class name to start getting down to the\n",
    "#   a sensor ID. Each sensor type has an ID number. We'll eventually need those ID numbers to be able to request values that come from\n",
    "#   that specific sensor.\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "\n",
    "response = request_list_info(request_template=request_data)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpqKOeV3pDvc"
   },
   "source": [
    "We're interested in getting to something that might be the Air Quality Index (AQI). You see this reported on the news - often around smog values, but also when there is smoke in the sky. The AQI is a complex measure of different gasses and of the particles in the air (dust, dirt, ash ...).\n",
    "\n",
    "From the list produced by our 'list/Classes' request above, it looks like there is a class of sensors called \"AQI POLLUTANTS\". Let's try to get a list of those specific sensors and see what we can get from those.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1CcLEf0mpDvc"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#   Once we have a list of the classes or groups of possible sensors, we can find the sensor IDs that make up that class (group)\n",
    "#   The one that looks to be associated with the Air Quality Index is \"AQI POLLUTANTS\"\n",
    "#   We'll use that to make another list request.\n",
    "#\n",
    "AQI_PARAM_CLASS = \"AQI POLLUTANTS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6mnhct-pDvc",
    "outputId": "fd7d76ff-d77a-4e7d-99da-b46c2b7ff5d4"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#   Structure a request to get the sensor IDs associated with the AQI\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['pclass'] = AQI_PARAM_CLASS  # here we specify that we want this 'pclass' or parameter classs\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_PARAMS)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRSB5Xm_pDvd"
   },
   "source": [
    "We should now have (above) a response containing a set of sensor ID numbers. The list should include the sensor numbers as well as a description or name for each sensor.\n",
    "\n",
    "The EPA AQS API has limits on some call parameters. Specifically, when we request data for sensors we can only specify a maximum of 5 different sensor values to return. This means we cannot get all of the Air Quality Index parameters in one request for data. We have to break it up.\n",
    "\n",
    "What I did below was to break the request into two logical groups, the AQI sensors that sample gasses and the AQI sensors that sample particles in the air."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "M38rJuWBpDvd"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#   Given the set of sensor codes, now we can create a parameter list or 'param' value as defined by the AQS API spec.\n",
    "#   It turns out that we want all of these measures for AQI, but we need to have two different param constants to get\n",
    "#   all seven of the code types. We can only have a max of 5 sensors/values request per param.\n",
    "#\n",
    "#   Gaseous AQI pollutants CO, SO2, NO2, and O2\n",
    "AQI_PARAMS_GASEOUS = \"42101,42401,42602,44201\"\n",
    "#\n",
    "#   Particulate AQI pollutants PM10, PM2.5, and Acceptable PM2.5\n",
    "AQI_PARAMS_PARTICULATES = \"81102,88101,88502\"\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AU_iusCXpDvd"
   },
   "source": [
    "Air quality monitoring stations are located all over the US at different locations. We will need some sample locations to experiment with different locations to see what kinds of values come back from different sensor requests.\n",
    "\n",
    "This list includes the [FIPS](https://www.census.gov/library/reference/code-lists/ansi.html) number for the state and county as a 5 digit string. This format, the 5 digit string, is a 'old' format that is still widely used. There are new codes that may eventually be adopted for the US government information systems. But FIPS is currently what the AQS uses, so that's what is in the list as the constant.\n",
    "\n",
    "Just two example cities to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining City Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My assigned city is Del Rio, Texas.\n",
    "After analysis I found no local sites of AQI meeasurement. Thus I used the bounding boxes to find a site and then used the same to extract the AQI information.\n",
    "Thus the 2nd info is for that specific site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rm3llmXTpDvd"
   },
   "outputs": [],
   "source": [
    "CITY_LOCATIONS = {\n",
    "    'del_rio' :       {'city'   : 'Del Rio',\n",
    "                       'county' : 'Val Verde',\n",
    "                       'state'  : 'Texas',\n",
    "                       'fips'   : '48465',\n",
    "                       'latlon' : [29.3692, -100.8908] },\n",
    "    'del_rio_nearby' :       {'county' : 'Brewster',\n",
    "                       'state'  : 'Texas',\n",
    "                       'fips'   : '48043'\n",
    "                             }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"0001\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0002\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0003\",\n",
      "        \"value_represented\": \"LAKE AMISTAD\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  This list request should give us a list of all the monitoring stations in the county specified by the\n",
    "#  given city selected from the CITY_LOCATIONS dictionary\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['state'] = CITY_LOCATIONS['del_rio']['fips'][:2]   # the first two digits (characters) of FIPS is the state code\n",
    "request_data['county'] = CITY_LOCATIONS['del_rio']['fips'][2:]  # the last three digits (characters) of FIPS is the county code\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_SITES)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are no closeby stations to Del Rio Texas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ySD7sUnpDve"
   },
   "source": [
    "## Making a daily summary request\n",
    "\n",
    "The function below is designed to encapsulate requests to the EPA AQS API. When calling the function one should create/copy a parameter template, then initialize that template with values that won't change with each call. Then on each call simply pass in the parameters that need to change, like date ranges.\n",
    "\n",
    "Another function below provides an example of extracting values and restructuring the response to make it a little more usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DJ0DlpLTpDve"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the daily summary request. Daily summary provides a daily summary value for each sensor being requested\n",
    "#    from the start date to the end date.\n",
    "#\n",
    "#    Like the two other functions, this can be called with a mixture of a defined parameter dictionary, or with function\n",
    "#    parameters. If function parameters are provided, those take precedence over any parameters from the request template.\n",
    "#\n",
    "def request_daily_summary(email_address = None, key = None, param=None,\n",
    "                          begin_date = None, end_date = None, fips = None,\n",
    "                          endpoint_url = API_REQUEST_URL,\n",
    "                          endpoint_action = API_ACTION_DAILY_SUMMARY_COUNTY,\n",
    "                          request_template = AQS_REQUEST_TEMPLATE,\n",
    "                          headers = None):\n",
    "\n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    if param:\n",
    "        request_template['param'] = param\n",
    "    if begin_date:\n",
    "        request_template['begin_date'] = begin_date\n",
    "    if end_date:\n",
    "        request_template['end_date'] = end_date\n",
    "    if fips and len(fips)==5:\n",
    "        request_template['state'] = fips[:2]\n",
    "        request_template['county'] = fips[2:]\n",
    "\n",
    "    # Make sure there are values that allow us to make a call - these are always required\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_daily_summary()'\")\n",
    "    if not request_template['key']:\n",
    "        raise Exception(\"Must supply a key to call 'request_daily_summary()'\")\n",
    "    if not request_template['param']:\n",
    "        raise Exception(\"Must supply param values to call 'request_daily_summary()'\")\n",
    "    if not request_template['begin_date']:\n",
    "        raise Exception(\"Must supply a begin_date to call 'request_daily_summary()'\")\n",
    "    if not request_template['end_date']:\n",
    "        raise Exception(\"Must supply an end_date to call 'request_daily_summary()'\")\n",
    "    # Note we're not validating FIPS fields because not all of the daily summary actions require the FIPS numbers\n",
    "\n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for the gaseous pollutants ...\n",
      "Looks like the response generated no data. You might take a closer look at your request and the response data.\n",
      "Response for the particulate pollutants ...\n",
      "Looks like the response generated no data. You might take a closer look at your request and the response data.\n"
     ]
    }
   ],
   "source": [
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_GASEOUS\n",
    "request_data['state'] = CITY_LOCATIONS['del_rio']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['del_rio']['fips'][2:]\n",
    "\n",
    "# request daily summary data for the month of July in 2021\n",
    "gaseous_aqi = request_daily_summary(request_template=request_data, begin_date=\"20210701\", end_date=\"20210731\")\n",
    "print(\"Response for the gaseous pollutants ...\")\n",
    "#\n",
    "if gaseous_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(gaseous_aqi['Data'],indent=4))\n",
    "elif gaseous_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "    print(\"Looks like the response generated no data. You might take a closer look at your request and the response data.\")\n",
    "else:\n",
    "    print(json.dumps(gaseous_aqi,indent=4))\n",
    "\n",
    "request_data['param'] = AQI_PARAMS_PARTICULATES\n",
    "# request daily summary data for the month of July in 2021\n",
    "particulate_aqi = request_daily_summary(request_template=request_data, begin_date=\"20210701\", end_date=\"20210731\")\n",
    "print(\"Response for the particulate pollutants ...\")\n",
    "#\n",
    "if particulate_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(particulate_aqi['Data'],indent=4))\n",
    "elif particulate_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "    print(\"Looks like the response generated no data. You might take a closer look at your request and the response data.\")\n",
    "else:\n",
    "    print(json.dumps(particulate_aqi,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We see that there is no AQI values for gaseous and particluate pollutants for this site. Thus we need to try the bounding boxes.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the daily summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "if5akhw2pDvg"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    This is a list of field names - data - that will be extracted from each record\n",
    "#\n",
    "EXTRACTION_FIELDS = ['sample_duration','observation_count','arithmetic_mean','aqi']\n",
    "\n",
    "#\n",
    "#    The function creates a summary record\n",
    "def extract_summary_from_response(r=None, fields=EXTRACTION_FIELDS):\n",
    "    ## the result will be structured around monitoring site, parameter, and then date\n",
    "    result = dict()\n",
    "    data = r[\"Data\"]\n",
    "    for record in data:\n",
    "        # make sure the record is set up\n",
    "        site = record['site_number']\n",
    "        param = record['parameter_code']\n",
    "        #date = record['date_local']    # this version keeps the respnse value YYYY-\n",
    "        date = record['date_local'].replace('-','') # this puts it in YYYYMMDD format\n",
    "        if site not in result:\n",
    "            result[site] = dict()\n",
    "            result[site]['local_site_name'] = record['local_site_name']\n",
    "            result[site]['site_address'] = record['site_address']\n",
    "            result[site]['state'] = record['state']\n",
    "            result[site]['county'] = record['county']\n",
    "            result[site]['city'] = record['city']\n",
    "            result[site]['pollutant_type'] = dict()\n",
    "        if param not in result[site]['pollutant_type']:\n",
    "            result[site]['pollutant_type'][param] = dict()\n",
    "            result[site]['pollutant_type'][param]['parameter_name'] = record['parameter']\n",
    "            result[site]['pollutant_type'][param]['units_of_measure'] = record['units_of_measure']\n",
    "            result[site]['pollutant_type'][param]['method'] = record['method']\n",
    "            result[site]['pollutant_type'][param]['data'] = dict()\n",
    "        if date not in result[site]['pollutant_type'][param]['data']:\n",
    "            result[site]['pollutant_type'][param]['data'][date] = list()\n",
    "\n",
    "        # now extract the specified fields\n",
    "        extract = dict()\n",
    "        for k in fields:\n",
    "            if str(k) in record:\n",
    "                extract[str(k)] = record[k]\n",
    "            else:\n",
    "                # this makes sure we always have the requested fields, even if\n",
    "                # we have a missing value for a given day/month\n",
    "                extract[str(k)] = None\n",
    "\n",
    "        # add this extraction to the list for the day\n",
    "        result[site]['pollutant_type'][param]['data'][date].append(extract)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmYgxS3jpDvg",
    "outputId": "0522b2ae-87f1-4900-a2f7-47d98da11ec5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of gaseous extraction ...\n",
      "{}\n",
      "Summary of particulate extraction ...\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "extract_gaseous = extract_summary_from_response(gaseous_aqi)\n",
    "print(\"Summary of gaseous extraction ...\")\n",
    "print(json.dumps(extract_gaseous,indent=4))\n",
    "\n",
    "extract_particulate = extract_summary_from_response(particulate_aqi)\n",
    "print(\"Summary of particulate extraction ...\")\n",
    "print(json.dumps(extract_particulate,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We get no summary for Del Rio, Texas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6KohgZKpDvg"
   },
   "source": [
    "## Making request by bounding box\n",
    "\n",
    "There are some places that don't have monitoring stations. In the EPA FAQ that covers the AQS system, they note that their monitoring covers 2000 of the 3000+ US counties.\n",
    "\n",
    "The AQS API has a mechanism of requesting data and monitoring stations using a geographic bounding box. The above examples just demonstrated the use of the AQS API for making requests by counties. The examples below illustrate the use of bounding boxes. The example below makes requests to identify monitoring stations within the bounding box. Once you knew you have monitoring stations, then the bounding box could be used in the daily summary requests to get AQS data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OjtRY4EVpDvg"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#   These are rough estimates for creating bounding boxes based on a city location\n",
    "#   You can find these rough estimates on the USGS website:\n",
    "#   https://www.usgs.gov/faqs/how-much-distance-does-a-degree-minute-and-second-cover-your-maps\n",
    "#\n",
    "LAT_25MILES = 25.0 * (1.0/69.0)    # This is about 25 miles of latitude in decimal degrees\n",
    "LON_25MILES = 25.0 * (1.0/54.6)    # This is about 25 miles of longitude in decimal degrees\n",
    "#\n",
    "#   Compute a rough estimates for a bounding box around a given place\n",
    "#   The bounding box is scaled in 50 mile increments. That is the bounding box will have sides that\n",
    "#   are rough multiples of 50 miles, with the center of the box around the indicated place.\n",
    "#   The scale parameter determines the scale (size) of the bounding box\n",
    "#\n",
    "def bounding_latlon(place=None,scale=1.0):\n",
    "    minlat = place['latlon'][0] - float(scale) * LAT_25MILES\n",
    "    maxlat = place['latlon'][0] + float(scale) * LAT_25MILES\n",
    "    minlon = place['latlon'][1] - float(scale) * LON_25MILES\n",
    "    maxlon = place['latlon'][1] + float(scale) * LON_25MILES\n",
    "    return [minlat,maxlat,minlon,maxlon]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MM-qVEpHpDvh"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the monitors request. This requests monitoring stations. This can be done by state, county, or bounding box.\n",
    "#\n",
    "#    Like the two other functions, this can be called with a mixture of a defined parameter dictionary, or with function\n",
    "#    parameters. If function parameters are provided, those take precedence over any parameters from the request template.\n",
    "#\n",
    "def request_monitors(email_address = None, key = None, param=None,\n",
    "                          begin_date = None, end_date = None, fips = None,\n",
    "                          endpoint_url = API_REQUEST_URL,\n",
    "                          endpoint_action = API_ACTION_MONITORS_COUNTY,\n",
    "                          request_template = AQS_REQUEST_TEMPLATE,\n",
    "                          headers = None):\n",
    "\n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    if param:\n",
    "        request_template['param'] = param\n",
    "    if begin_date:\n",
    "        request_template['begin_date'] = begin_date\n",
    "    if end_date:\n",
    "        request_template['end_date'] = end_date\n",
    "    if fips and len(fips)==5:\n",
    "        request_template['state'] = fips[:2]\n",
    "        request_template['county'] = fips[2:]\n",
    "\n",
    "    # Make sure there are values that allow us to make a call - these are always required\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_monitors()'\")\n",
    "    if not request_template['key']:\n",
    "        raise Exception(\"Must supply a key to call 'request_monitors()'\")\n",
    "    if not request_template['param']:\n",
    "        raise Exception(\"Must supply param values to call 'request_monitors()'\")\n",
    "    if not request_template['begin_date']:\n",
    "        raise Exception(\"Must supply a begin_date to call 'request_monitors()'\")\n",
    "    if not request_template['end_date']:\n",
    "        raise Exception(\"Must supply an end_date to call 'request_monitors()'\")\n",
    "    # Note we're not validating FIPS fields because not all of the monitors actions require the FIPS numbers\n",
    "\n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Kkhc-J_pDvh"
   },
   "source": [
    "##  Data Request using a bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUPYykwqpDvh",
    "outputId": "87dade51-16e3-41f7-f8bc-c74bad5c016b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"state_code\": \"48\",\n",
      "        \"county_code\": \"479\",\n",
      "        \"site_number\": \"0313\",\n",
      "        \"parameter_code\": \"88101\",\n",
      "        \"poc\": 1,\n",
      "        \"parameter_name\": \"PM2.5 - Local Conditions\",\n",
      "        \"open_date\": \"2018-03-28\",\n",
      "        \"close_date\": null,\n",
      "        \"concurred_exclusions\": null,\n",
      "        \"dominant_source\": null,\n",
      "        \"measurement_scale\": \"MICROSCALE\",\n",
      "        \"measurement_scale_def\": \"0 M TO 100 M\",\n",
      "        \"monitoring_objective\": \"SOURCE ORIENTED\",\n",
      "        \"last_method_code\": \"209\",\n",
      "        \"last_method_description\": \"Met One BAM-1022 Mass Monitor w/ VSCC or TE-PM2.5C - Beta Attenuation\",\n",
      "        \"last_method_begin_date\": \"2018-03-28\",\n",
      "        \"naaqs_primary_monitor\": \"Y\",\n",
      "        \"qa_primary_monitor\": null,\n",
      "        \"monitor_type\": \"SLAMS\",\n",
      "        \"networks\": null,\n",
      "        \"monitoring_agency_code\": \"1035\",\n",
      "        \"monitoring_agency\": \"Texas Commission On Environmental Quality\",\n",
      "        \"si_id\": 91203,\n",
      "        \"latitude\": 27.599444,\n",
      "        \"longitude\": -99.533333,\n",
      "        \"datum\": \"WGS84\",\n",
      "        \"lat_lon_accuracy\": 5.0,\n",
      "        \"elevation\": 146.0,\n",
      "        \"probe_height\": null,\n",
      "        \"pl_probe_location\": null,\n",
      "        \"local_site_name\": \"World Trade Bridge\",\n",
      "        \"address\": \"Mines Road 11601 FM 1472\",\n",
      "        \"state_name\": \"Texas\",\n",
      "        \"county_name\": \"Webb\",\n",
      "        \"city_name\": \"Laredo\",\n",
      "        \"cbsa_code\": \"29700\",\n",
      "        \"cbsa_name\": \"Laredo, TX\",\n",
      "        \"csa_code\": null,\n",
      "        \"csa_name\": null,\n",
      "        \"tribal_code\": null,\n",
      "        \"tribe_name\": null\n",
      "    },\n",
      "    {\n",
      "        \"state_code\": \"48\",\n",
      "        \"county_code\": \"029\",\n",
      "        \"site_number\": \"0032\",\n",
      "        \"parameter_code\": \"88101\",\n",
      "        \"poc\": 2,\n",
      "        \"parameter_name\": \"PM2.5 - Local Conditions\",\n",
      "        \"open_date\": \"2018-11-08\",\n",
      "        \"close_date\": null,\n",
      "        \"concurred_exclusions\": null,\n",
      "        \"dominant_source\": null,\n",
      "        \"measurement_scale\": \"URBAN SCALE\",\n",
      "        \"measurement_scale_def\": \"4 KM TO 50 KM\",\n",
      "        \"monitoring_objective\": \"POPULATION EXPOSURE\",\n",
      "        \"last_method_code\": \"209\",\n",
      "        \"last_method_description\": \"Met One BAM-1022 Mass Monitor w/ VSCC or TE-PM2.5C - Beta Attenuation\",\n",
      "        \"last_method_begin_date\": \"2018-11-08\",\n",
      "        \"naaqs_primary_monitor\": null,\n",
      "        \"qa_primary_monitor\": \"Y\",\n",
      "        \"monitor_type\": \"SLAMS\",\n",
      "        \"networks\": null,\n",
      "        \"monitoring_agency_code\": \"1035\",\n",
      "        \"monitoring_agency\": \"Texas Commission On Environmental Quality\",\n",
      "        \"si_id\": 15106,\n",
      "        \"latitude\": 29.51509,\n",
      "        \"longitude\": -98.620166,\n",
      "        \"datum\": \"WGS84\",\n",
      "        \"lat_lon_accuracy\": 5.01,\n",
      "        \"elevation\": 279.5,\n",
      "        \"probe_height\": null,\n",
      "        \"pl_probe_location\": null,\n",
      "        \"local_site_name\": \"San Antonio Northwest\",\n",
      "        \"address\": \"6655 Bluebird Lane\",\n",
      "        \"state_name\": \"Texas\",\n",
      "        \"county_name\": \"Bexar\",\n",
      "        \"city_name\": \"San Antonio\",\n",
      "        \"cbsa_code\": \"41700\",\n",
      "        \"cbsa_name\": \"San Antonio-New Braunfels, TX\",\n",
      "        \"csa_code\": null,\n",
      "        \"csa_name\": null,\n",
      "        \"tribal_code\": null,\n",
      "        \"tribe_name\": null\n",
      "    },\n",
      "    {\n",
      "        \"state_code\": \"48\",\n",
      "        \"county_code\": \"043\",\n",
      "        \"site_number\": \"0101\",\n",
      "        \"parameter_code\": \"88502\",\n",
      "        \"poc\": 1,\n",
      "        \"parameter_name\": \"Acceptable PM2.5 AQI & Speciation Mass\",\n",
      "        \"open_date\": \"1988-03-02\",\n",
      "        \"close_date\": null,\n",
      "        \"concurred_exclusions\": null,\n",
      "        \"dominant_source\": null,\n",
      "        \"measurement_scale\": \"REGIONAL SCALE\",\n",
      "        \"measurement_scale_def\": \"50 TO HUNDREDS KM\",\n",
      "        \"monitoring_objective\": \"GENERAL/BACKGROUND\",\n",
      "        \"last_method_code\": \"707\",\n",
      "        \"last_method_description\": \"IMPROVE Module A with Cyclone Inlet-Teflon Filter, 2.2 sq. cm. - GRAVIMETRIC\",\n",
      "        \"last_method_begin_date\": \"1999-07-28\",\n",
      "        \"naaqs_primary_monitor\": null,\n",
      "        \"qa_primary_monitor\": null,\n",
      "        \"monitor_type\": \"EPA\",\n",
      "        \"networks\": \"IMPROVE\",\n",
      "        \"monitoring_agency_code\": \"0745\",\n",
      "        \"monitoring_agency\": \"National Park Service\",\n",
      "        \"si_id\": 15147,\n",
      "        \"latitude\": 29.30265,\n",
      "        \"longitude\": -103.17781,\n",
      "        \"datum\": \"WGS84\",\n",
      "        \"lat_lon_accuracy\": 5.0,\n",
      "        \"elevation\": 1057.0,\n",
      "        \"probe_height\": null,\n",
      "        \"pl_probe_location\": null,\n",
      "        \"local_site_name\": \"Big Bend NP - K-Bar Ranch Road\",\n",
      "        \"address\": \"BIG BEND NATIONAL PARK, TEXAS\",\n",
      "        \"state_name\": \"Texas\",\n",
      "        \"county_name\": \"Brewster\",\n",
      "        \"city_name\": \"Not in a City\",\n",
      "        \"cbsa_code\": null,\n",
      "        \"cbsa_name\": null,\n",
      "        \"csa_code\": null,\n",
      "        \"csa_name\": null,\n",
      "        \"tribal_code\": null,\n",
      "        \"tribe_name\": null\n",
      "    },\n",
      "    {\n",
      "        \"state_code\": \"48\",\n",
      "        \"county_code\": \"323\",\n",
      "        \"site_number\": \"0004\",\n",
      "        \"parameter_code\": \"88101\",\n",
      "        \"poc\": 1,\n",
      "        \"parameter_name\": \"PM2.5 - Local Conditions\",\n",
      "        \"open_date\": \"2018-03-28\",\n",
      "        \"close_date\": null,\n",
      "        \"concurred_exclusions\": null,\n",
      "        \"dominant_source\": null,\n",
      "        \"measurement_scale\": \"REGIONAL SCALE\",\n",
      "        \"measurement_scale_def\": \"50 TO HUNDREDS KM\",\n",
      "        \"monitoring_objective\": \"REGIONAL TRANSPORT\",\n",
      "        \"last_method_code\": \"209\",\n",
      "        \"last_method_description\": \"Met One BAM-1022 Mass Monitor w/ VSCC or TE-PM2.5C - Beta Attenuation\",\n",
      "        \"last_method_begin_date\": \"2018-03-28\",\n",
      "        \"naaqs_primary_monitor\": \"Y\",\n",
      "        \"qa_primary_monitor\": null,\n",
      "        \"monitor_type\": \"SPM\",\n",
      "        \"networks\": null,\n",
      "        \"monitoring_agency_code\": \"1035\",\n",
      "        \"monitoring_agency\": \"Texas Commission On Environmental Quality\",\n",
      "        \"si_id\": 92508,\n",
      "        \"latitude\": 28.704607,\n",
      "        \"longitude\": -100.451156,\n",
      "        \"datum\": \"WGS84\",\n",
      "        \"lat_lon_accuracy\": 5.01,\n",
      "        \"elevation\": 255.0,\n",
      "        \"probe_height\": null,\n",
      "        \"pl_probe_location\": null,\n",
      "        \"local_site_name\": \"Eagle Pass\",\n",
      "        \"address\": \"265 Foster Maldonado\",\n",
      "        \"state_name\": \"Texas\",\n",
      "        \"county_name\": \"Maverick\",\n",
      "        \"city_name\": \"Eagle Pass\",\n",
      "        \"cbsa_code\": \"20580\",\n",
      "        \"cbsa_name\": \"Eagle Pass, TX\",\n",
      "        \"csa_code\": null,\n",
      "        \"csa_name\": null,\n",
      "        \"tribal_code\": null,\n",
      "        \"tribe_name\": null\n",
      "    },\n",
      "    {\n",
      "        \"state_code\": \"48\",\n",
      "        \"county_code\": \"043\",\n",
      "        \"site_number\": \"0101\",\n",
      "        \"parameter_code\": \"88101\",\n",
      "        \"poc\": 1,\n",
      "        \"parameter_name\": \"PM2.5 - Local Conditions\",\n",
      "        \"open_date\": \"2017-05-05\",\n",
      "        \"close_date\": null,\n",
      "        \"concurred_exclusions\": null,\n",
      "        \"dominant_source\": null,\n",
      "        \"measurement_scale\": \"REGIONAL SCALE\",\n",
      "        \"measurement_scale_def\": \"50 TO HUNDREDS KM\",\n",
      "        \"monitoring_objective\": \"GENERAL/BACKGROUND\",\n",
      "        \"last_method_code\": \"209\",\n",
      "        \"last_method_description\": \"Met One BAM-1022 Mass Monitor w/ VSCC or TE-PM2.5C - Beta Attenuation\",\n",
      "        \"last_method_begin_date\": \"2017-05-05\",\n",
      "        \"naaqs_primary_monitor\": \"Y\",\n",
      "        \"qa_primary_monitor\": null,\n",
      "        \"monitor_type\": \"SPM\",\n",
      "        \"networks\": null,\n",
      "        \"monitoring_agency_code\": \"1035\",\n",
      "        \"monitoring_agency\": \"Texas Commission On Environmental Quality\",\n",
      "        \"si_id\": 15147,\n",
      "        \"latitude\": 29.30265,\n",
      "        \"longitude\": -103.17781,\n",
      "        \"datum\": \"WGS84\",\n",
      "        \"lat_lon_accuracy\": 5.0,\n",
      "        \"elevation\": 1057.0,\n",
      "        \"probe_height\": null,\n",
      "        \"pl_probe_location\": null,\n",
      "        \"local_site_name\": \"Big Bend NP - K-Bar Ranch Road\",\n",
      "        \"address\": \"BIG BEND NATIONAL PARK, TEXAS\",\n",
      "        \"state_name\": \"Texas\",\n",
      "        \"county_name\": \"Brewster\",\n",
      "        \"city_name\": \"Not in a City\",\n",
      "        \"cbsa_code\": null,\n",
      "        \"cbsa_name\": null,\n",
      "        \"csa_code\": null,\n",
      "        \"csa_name\": null,\n",
      "        \"tribal_code\": null,\n",
      "        \"tribe_name\": null\n",
      "    },\n",
      "    {\n",
      "        \"state_code\": \"48\",\n",
      "        \"county_code\": \"029\",\n",
      "        \"site_number\": \"0032\",\n",
      "        \"parameter_code\": \"88101\",\n",
      "        \"poc\": 1,\n",
      "        \"parameter_name\": \"PM2.5 - Local Conditions\",\n",
      "        \"open_date\": \"2008-01-01\",\n",
      "        \"close_date\": null,\n",
      "        \"concurred_exclusions\": null,\n",
      "        \"dominant_source\": null,\n",
      "        \"measurement_scale\": \"URBAN SCALE\",\n",
      "        \"measurement_scale_def\": \"4 KM TO 50 KM\",\n",
      "        \"monitoring_objective\": \"QUALITY ASSURANCE\",\n",
      "        \"last_method_code\": \"145\",\n",
      "        \"last_method_description\": \"R & P Model 2025 PM-2.5 Sequential Air Sampler w/VSCC - Gravimetric\",\n",
      "        \"last_method_begin_date\": \"2008-01-01\",\n",
      "        \"naaqs_primary_monitor\": \"Y\",\n",
      "        \"qa_primary_monitor\": null,\n",
      "        \"monitor_type\": \"SLAMS\",\n",
      "        \"networks\": null,\n",
      "        \"monitoring_agency_code\": \"1035\",\n",
      "        \"monitoring_agency\": \"Texas Commission On Environmental Quality\",\n",
      "        \"si_id\": 15106,\n",
      "        \"latitude\": 29.51509,\n",
      "        \"longitude\": -98.620166,\n",
      "        \"datum\": \"WGS84\",\n",
      "        \"lat_lon_accuracy\": 5.01,\n",
      "        \"elevation\": 279.5,\n",
      "        \"probe_height\": null,\n",
      "        \"pl_probe_location\": null,\n",
      "        \"local_site_name\": \"San Antonio Northwest\",\n",
      "        \"address\": \"6655 Bluebird Lane\",\n",
      "        \"state_name\": \"Texas\",\n",
      "        \"county_name\": \"Bexar\",\n",
      "        \"city_name\": \"San Antonio\",\n",
      "        \"cbsa_code\": \"41700\",\n",
      "        \"cbsa_name\": \"San Antonio-New Braunfels, TX\",\n",
      "        \"csa_code\": null,\n",
      "        \"csa_name\": null,\n",
      "        \"tribal_code\": null,\n",
      "        \"tribe_name\": null\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#    Create a copy of the AQS_REQUEST_TEMPLATE\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_PARTICULATES     # same particulate request as the one abover\n",
    "#\n",
    "#   Not going to use these - comment them out\n",
    "#request_data['state'] = CITY_LOCATIONS['bend']['fips'][:2]\n",
    "#request_data['county'] = CITY_LOCATIONS['bend']['fips'][2:]\n",
    "#\n",
    "#   Now, we need bounding box parameters\n",
    "\n",
    "#   50 mile box\n",
    "#bbox = bounding_latlon(CITY_LOCATIONS['del_rio'],scale=1.0)\n",
    "#   100 mile box\n",
    "#bbox = bounding_latlon(CITY_LOCATIONS['del_rio'],scale=2.0)\n",
    "#   150 mile box\n",
    "# bbox = bounding_latlon(CITY_LOCATIONS['del_rio'],scale=3.0)\n",
    "#   200 mile box\n",
    "# bbox = bounding_latlon(CITY_LOCATIONS['del_rio'],scale=4.0)\n",
    "#   250 mile box\n",
    "bbox = bounding_latlon(CITY_LOCATIONS['del_rio'],scale=5.0)\n",
    "\n",
    "# the bbox response comes back as a list - [minlat,maxlat,minlon,maxlon]\n",
    "\n",
    "#   put our bounding box into the request_data\n",
    "request_data['minlat'] = bbox[0]\n",
    "request_data['maxlat'] = bbox[1]\n",
    "request_data['minlon'] = bbox[2]\n",
    "request_data['maxlon'] = bbox[3]\n",
    "\n",
    "#\n",
    "#   we need to change the action for the API from the default to the bounding box - same recent date for now\n",
    "response = request_monitors(request_template=request_data, begin_date=\"20210701\", end_date=\"20210731\",\n",
    "                            endpoint_action = API_ACTION_MONITORS_BOX)\n",
    "#\n",
    "#\n",
    "#\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del Rio is very remote and lies on the border of Mexico. Thus to get the monitoring stations, I had to increase the bounding boxes to a higher range. I found good 5 Monitoring stations around Del Rio, Texas. when I increased the bounding box scale to 250 Miles and finalized a fips number such that I have maximum AQI data.\n",
    "**I finalized monitoring station in Brewster, Texas with fips=48043 which started in 1988 to get as close AQI data as possible to 1963**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-running the AQI extraction for city location = del_rio_nearby with fips=48043 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AsLN-WZZpDve",
    "outputId": "54987910-6059-4cb0-851d-afc4cc8922f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"0001\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0002\",\n",
      "        \"value_represented\": \"SUL ROSS UNIVERSITY\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0101\",\n",
      "        \"value_represented\": \"Big Bend NP - K-Bar Ranch Road\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  This list request should give us a list of all the monitoring stations in the county specified by the\n",
    "#  given city selected from the CITY_LOCATIONS dictionary\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['state'] = CITY_LOCATIONS['del_rio_nearby']['fips'][:2]   # the first two digits (characters) of FIPS is the state code\n",
    "request_data['county'] = CITY_LOCATIONS['del_rio_nearby']['fips'][2:]  # the last three digits (characters) of FIPS is the county code\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_SITES)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We see multiple stations now and hope to find good AQI data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AQI data extraction from 1963 to 2023 for monitoring station in Brewster Texas for Del Rio Texas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will extract daily AQI information for the monitoring station in Brewster Texas. I used a for loop to extract yearly data for these 60 years. The code will extract both gaseous and particulate AQI and store all of it as data frame extracted from dictionary format.\n",
    "I then combine the dataframes and extract only the date, AQI and pollutant type for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Fz6dzbYpDvf",
    "outputId": "0cd6e841-1414-4cde-9a3e-bc94fe7d6e50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Years: 100%|| 60/60 [01:15<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# Requesting to get AQI values daily from 1963 onwards\n",
    "# The Final data will have AQI values recorded every day at Brewster Texas\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_GASEOUS\n",
    "request_data['state'] = '48' #CITY_LOCATIONS['del_rio']['fips'][:2]\n",
    "request_data['county'] = '043' #CITY_LOCATIONS['del_rio']['fips'][2:]\n",
    "year_list = range(1963,2023)\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for  i in tqdm(year_list, position=0, leave=True, desc=\"Years\"):\n",
    "    # request daily summary data for a year\n",
    "    gaseous_aqi = request_daily_summary(request_template=request_data, begin_date=str(i)+\"0101\", end_date=str(i)+\"1231\")\n",
    "    # print(\"Response for the gaseous pollutants ...\")\n",
    "    #\n",
    "    if gaseous_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        gaseous_aqi_df = pd.DataFrame(gaseous_aqi['Data'])[['date_local','pollutant_standard','aqi']]\n",
    "        # print(json.dumps(gaseous_aqi['Data'],indent=4))\n",
    "    # elif gaseous_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "    #     print(\"Looks like the response generated no data. You might take a closer look at your request and the response data.\")\n",
    "    else:\n",
    "        gaseous_aqi_df = pd.DataFrame()\n",
    "        #print(json.dumps(gaseous_aqi,indent=4))\n",
    "\n",
    "    request_data['param'] = AQI_PARAMS_PARTICULATES\n",
    "    # request daily summary data for a year\n",
    "    particulate_aqi = request_daily_summary(request_template=request_data, begin_date=str(i)+\"0101\", end_date=str(i)+\"1231\")\n",
    "    # print(\"Response for the particulate pollutants ...\")\n",
    "    #\n",
    "    if particulate_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        particulate_aqi_df = pd.DataFrame(particulate_aqi['Data'])[['date_local','pollutant_standard','aqi']]\n",
    "        # print(json.dumps(particulate_aqi['Data'],indent=4))\n",
    "    # elif particulate_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "    #     print(\"Looks like the response generated no data. You might take a closer look at your request and the response data.\")\n",
    "    else:\n",
    "        particulate_aqi_df = pd.DataFrame()\n",
    "        #print(json.dumps(particulate_aqi,indent=4))\n",
    "\n",
    "    aqi_df = pd.concat([gaseous_aqi_df,particulate_aqi_df])\n",
    "    final_df = pd.concat([final_df,aqi_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "yIDYYzuGpDvf",
    "outputId": "fc82ff67-8d25-43aa-a6e4-745bf2329f3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_local</th>\n",
       "      <th>pollutant_standard</th>\n",
       "      <th>aqi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1988-03-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988-03-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1988-03-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1988-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1988-03-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1988-04-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1988-04-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_local pollutant_standard   aqi\n",
       "0  1988-03-02                NaN  20.0\n",
       "1  1988-03-05                NaN  18.0\n",
       "2  1988-03-09                NaN  23.0\n",
       "3  1988-03-16                NaN  46.0\n",
       "4  1988-03-19                NaN  11.0\n",
       "5  1988-03-23                NaN  34.0\n",
       "6  1988-03-26                NaN  39.0\n",
       "7  1988-03-30                NaN  37.0\n",
       "8  1988-04-02                NaN  17.0\n",
       "9  1988-04-06                NaN  42.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the head of final data\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_local</th>\n",
       "      <th>pollutant_standard</th>\n",
       "      <th>aqi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53548</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53549</th>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53550</th>\n",
       "      <td>2022-12-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53551</th>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53552</th>\n",
       "      <td>2022-12-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53553</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53554</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53555</th>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53556</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53557</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_local pollutant_standard   aqi\n",
       "53548  2022-12-04                NaN  21.0\n",
       "53549  2022-12-07                NaN  13.0\n",
       "53550  2022-12-10                NaN  52.0\n",
       "53551  2022-12-13                NaN  18.0\n",
       "53552  2022-12-16                NaN   8.0\n",
       "53553  2022-12-19                NaN  14.0\n",
       "53554  2022-12-22                NaN  20.0\n",
       "53555  2022-12-25                NaN  11.0\n",
       "53556  2022-12-28                NaN  16.0\n",
       "53557  2022-12-31                NaN   6.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking tail of final df\n",
    "final_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the Data frame into a CSV for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "OkgFIzDvyo7G"
   },
   "outputs": [],
   "source": [
    "# Savinhg the Final Data\n",
    "final_df.to_csv('final_aqi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QM78YkN8pDvi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
